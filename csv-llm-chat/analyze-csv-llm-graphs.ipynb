{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7dc7e39-dd9a-43e3-8d9a-f77af583004c",
   "metadata": {},
   "source": [
    "### Dell Technologies Proof of Concept - CHAT, ANALYZE AND GRAPH YOUR CSV DATA WITH MISTRAL LLM\n",
    "- Model:  Mistral instruct v2\n",
    "- Workload:  CSV analysis using LLM\n",
    "- Orchestrator:  Langchain csv agent\n",
    "- Dataset:  hospital visits\n",
    "\n",
    "Note: The software and sample files are provided “as is” and are to be used only in conjunction with this POC application. They should not be used in production and are provided without warranty or guarantees. Please use them at your own discretion.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbcd722",
   "metadata": {},
   "source": [
    "### Huggingface tools\n",
    "\n",
    "You will need to at least log in once to get the hub for tools and the embedding model.  After that you can comment this section out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d4d542-e238-4948-ade3-efb972c78cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: fineGrained).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/daol/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "## code to auto login to hugging face, avoid the login prompt\n",
    "\n",
    "# get your account token from https://huggingface.co/settings/tokens\n",
    "# this is a read-only test token\n",
    "\n",
    "token = 'Put your token here'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b1132dd-4463-45fe-997f-2136c13464af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check installed GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0a0592-b751-4f5c-b97c-5cd12e8baef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan  2 03:27:36 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L40S                    Off |   00000000:61:00.0 Off |                    0 |\n",
      "| N/A   37C    P0             83W /  350W |   32125MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA L40S                    Off |   00000000:E1:00.0 Off |                    0 |\n",
      "| N/A   37C    P0             81W /  350W |    2071MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   2629103      C   ...ample/csv-llm-chat/.venv/bin/python      28306MiB |\n",
      "|    0   N/A  N/A   2663928      C   ...xample/RAG-docker/.venv/bin/python3       3808MiB |\n",
      "|    1   N/A  N/A   2663928      C   ...xample/RAG-docker/.venv/bin/python3       2064MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb3e4a-af6a-4852-98a0-97afaff2924c",
   "metadata": {},
   "source": [
    "### Assign GPU environment vars and ID order\n",
    "\n",
    "NOTE:  to change which GPU you want visible, simply change the CUDA VISIBLE DEVICES ID to the GPU you prefer. \n",
    "This method guarantees no confusion or misplaced workloads on any GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88bf410b-3b71-4299-8bc9-0b6fb09f4482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THESE VARIABLES MUST APPEAR BEFORE TORCH OR CUDA IS IMPORTED\n",
    "## set visible GPU devices and order of IDs to the PCI bus order\n",
    "## target the L40s that is on ID 1\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"   \n",
    "\n",
    "## this integer corresponds to the ID of the GPU, for multiple GPU use \"0,1,2,3\"...\n",
    "## to disable all GPUs, simply put empty quotes \"\"\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846fa67-69d7-478e-995e-d16a5ba98f72",
   "metadata": {},
   "source": [
    "### Investigate our GPU and CUDA environment\n",
    "\n",
    "NOTE:  If you are only using 1 single GPU in the visibility settings above, then the active CUDA device will always be 0 since it is the only GPU seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eaec1edd-9c18-4b1f-a0e8-e3ed03b3141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____Python, Pytorch, Cuda info____\n",
      "__Python VERSION: 3.12.8 (main, Dec  6 2024, 19:59:28) [Clang 18.1.8 ]\n",
      "__pyTorch VERSION: 2.5.1+cu124\n",
      "__CUDA RUNTIME API VERSION\n",
      "__CUDNN VERSION: 90100\n",
      "_____nvidia-smi GPU details____\n",
      "index, name, driver_version, memory.total [MiB], memory.used [MiB], memory.free [MiB]\n",
      "0, NVIDIA L40S, 550.120, 46068 MiB, 32125 MiB, 13465 MiB\n",
      "1, NVIDIA L40S, 550.120, 46068 MiB, 2071 MiB, 43519 MiB\n",
      "_____Device assignments____\n",
      "Number CUDA Devices: 1\n",
      "Current cuda device:  0  **May not correspond to nvidia-smi ID above, check visibility parameter\n",
      "Device name:  NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "from subprocess import call\n",
    "print('_____Python, Pytorch, Cuda info____')\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA RUNTIME API VERSION')\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('_____nvidia-smi GPU details____')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('_____Device assignments____')\n",
    "print('Number CUDA Devices:', torch.cuda.device_count())\n",
    "print ('Current cuda device: ', torch.cuda.current_device(), ' **May not correspond to nvidia-smi ID above, check visibility parameter')\n",
    "print(\"Device name: \", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bae0d5-b6ef-425b-9e29-13393a839bcf",
   "metadata": {},
   "source": [
    "### Assign single GPU to device variable\n",
    "\n",
    "This command assigns GPU ID 0 to the DEVICE variable called \"cuda:0\" if pytorch can actually reach and speak with the GPU using cuda language.  Else it will use the cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26efcc3-328c-49fe-9fe6-bbdbec423b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64b727-3bae-4f17-a0b9-35a29915b2df",
   "metadata": {},
   "source": [
    "### View csv contents and structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f9d50b3-3770-4b8e-abe6-37f4997cd6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('csv-files/healthcare.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad16fefb-1399-47b0-a7e6-6a55be010f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient Name Date of Birth  Age Reason for Admission       Procedure  \\\n",
      "0    Patient_3      8/6/2004   19                COVID  antiviral meds   \n",
      "1   Patient_39     3/19/2004   19                COVID  oxygen therapy   \n",
      "2   Patient_33     12/8/2002   21                COVID  oxygen therapy   \n",
      "\n",
      "       Room Date of Discharge  Length of Stay   Charges  Balance Remaining  \n",
      "0  Room_237        12/27/2023               0    237.34              37.34  \n",
      "1  Room_440         1/12/2024              22  29980.84            3018.84  \n",
      "2  Room_298        12/31/2023               6   4028.77            2681.26  \n"
     ]
    }
   ],
   "source": [
    "df_rows = df.head(3)\n",
    "print(df_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afe93d0-0641-4a57-8efb-bb8a4941dfdc",
   "metadata": {},
   "source": [
    "### Import CSV agent dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76ae7daa-2150-4880-82c5-4046a8a5ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f02c7468-c1e5-4553-8573-4eca197c4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.globals import set_verbose, set_debug\n",
    "# set_debug(True)\n",
    "# set_verbose(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281d086e-cc14-4635-b466-f02637bb80c6",
   "metadata": {},
   "source": [
    "### Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ecb659-43a1-49fd-9bcd-ddf0e128b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"mistralai/Mistral-7B-Instruct-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf2bce85-0888-44a0-ac76-27e027c7c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78eceb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://huggingface.co/docs/transformers/en/main_classes/quantization\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    ") \n",
    "\n",
    "# if you want use quantize 4bit, then quantize = True.  \n",
    "quantize = False\n",
    "if quantize:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "            model, \n",
    "            quantization_config=bnb_config, \n",
    "            device_map=\"auto\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b85df2ef-09b6-4427-8f84-90aafd3d19c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482e3b6de4244f738b6a13180adbee51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device because they were offloaded to the cpu.\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    max_new_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c127e37-8966-4e22-95a0-029a4dc56a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = HuggingFacePipeline(pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1e379-f815-4d8d-829f-74209644a401",
   "metadata": {},
   "source": [
    "### Initiate CSV agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b14f21f5-b9ca-4fea-9c3c-7905d52d55e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_csv_agent(\n",
    "    local_llm,\n",
    "    \"csv-files/healthcare.csv\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece424c3-875a-4e5c-be01-8d1913bb06ca",
   "metadata": {},
   "source": [
    "### Generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdbbb292-6242-4559-852a-c6cc45f9ace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I need to find the row in the dataframe that corresponds to patient 3 and then extract the procedure column for that row.\n",
      "Action: df\n",
      "Action Input: df.loc[df['Patient Name'] == 'Patient_3', 'Procedure']\u001b[0mdf is not a valid tool, try one of [python_repl_ast]."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to use the python shell to execute the command.\n",
      "Action: python_repl_ast\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answer. 'Patient_3', 'Procedure'].tolist()[0]\u001b[0m\u001b[36;1m\u001b[1;3mantiviral meds\u001b[0m\n",
      "Final Answer: The procedure for patient 3 was antiviral meds.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What was the procedure for patient 3?', 'output': 'The procedure for patient 3 was antiviral meds.'}\n"
     ]
    }
   ],
   "source": [
    "res = agent.invoke(\"What was the procedure for patient 3?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75466a3-381e-4edc-824a-e8f182026256",
   "metadata": {},
   "source": [
    "##### Compare to correct answer:  antiviral meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1624664a-c9a3-49ae-b471-eef40280653c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I need to find the row where the patient age is 21\n",
      "Action: df.loc\n",
      "Action Input: df.loc[df['Age'] == 21]\u001b[0mdf.loc is not a valid tool, try one of [python_repl_ast]."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to use the indexing of the dataframe to find the row where the patient age is 21\n",
      "Action: df.iloc\n",
      "Action Input: df.iloc[df.index[df['Age'] == 21].values[0]]\u001b[0mdf.iloc is not a valid tool, try one of [python_repl_ast]."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to use the indexing of the dataframe to find the row where the patient age is 21 and then extract the date of discharge and length of stay columns\n",
      "Action: df.iloc\n",
      "Action Input: df.iloc[df.index[df['Age'] == 21].values[0]][['Date of Discharge', 'Length of Stay']]\u001b[0mdf.iloc is not a valid tool, try one of [python_repl_ast]."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to use the indexing of the dataframe to find the row where the patient age is 21 and then extract the date of discharge and length of stay columns and assign them to variables\n",
      "Action: python_repl_ast\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answere'] == 21].values[0]][['Date of Discharge', 'Length of Stay']].values[0]\u001b[0m\u001b[36;1m\u001b[1;3m\u001b[0m\n",
      "Final Answer: The date of discharge for patient 21 is {x[0]} and the length of stay is {x[1]}\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What was date of discharge and length of stay for patient 21?', 'output': 'The date of discharge for patient 21 is {x[0]} and the length of stay is {x[1]}'}\n"
     ]
    }
   ],
   "source": [
    "res = agent.invoke(\"What was date of discharge and length of stay for patient 21?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02bf661-f6ac-493f-b65c-da697be1f423",
   "metadata": {},
   "source": [
    "##### Compare to correct answer:  11/15/2023 and the length of stay was 18 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8737bedf-cdc7-4431-a199-69e0f0d8f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I need to find the unique reasons for admission from the dataframe.\n",
      "Action: python_repl_ast\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answer.nique()\u001b[0m\u001b[36;1m\u001b[1;3m['COVID' 'Flu' 'Pneumonia' 'Heart attack' 'Stroke']\u001b[0m\n",
      "Final Answer: ['COVID', 'Flu', 'Pneumonia', 'Heart attack', 'Stroke']\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What are the unique reasons for admission?', 'output': \"['COVID', 'Flu', 'Pneumonia', 'Heart attack', 'Stroke']\"}\n"
     ]
    }
   ],
   "source": [
    "res = agent.invoke(\"What are the unique reasons for admission?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7aba0-f5ac-4831-826b-399934ef0198",
   "metadata": {},
   "source": [
    "##### Compare to correct answer:  COVID', 'Flu', 'Pneumonia', 'Heart attack', 'Stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67868a33-aed3-4fc9-829c-07e92529247f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m\n",
      "Thought: I need to group the dataframe by the reason for admission and then find the maximum charges for each group.\n",
      "Action: python_repl_ast\n",
      "Action Input: df.groupby('Reason for Admission')['Charges'].max()\u001b[0m\u001b[36;1m\u001b[1;3mReason for Admission\n",
      "COVID           29980.84\n",
      "Flu              9890.30\n",
      "Heart attack    15440.26\n",
      "Pneumonia        7820.46\n",
      "Stroke           8475.26\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
      "Final Answer: The reason for admission with the highest cost was COVID, with a total charge of 29980.84.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Cross reference the charges with the reason for admission to determine which reason had the highest cost.', 'output': 'The reason for admission with the highest cost was COVID, with a total charge of 29980.84.'}\n"
     ]
    }
   ],
   "source": [
    "res = agent.invoke(\"Cross reference the charges with the reason for admission to determine which reason had the highest cost.\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab652d1-5b5f-446d-abb5-71a0153af2d5",
   "metadata": {},
   "source": [
    "##### Correct answer:  highest cost was COVID, with a total cost of 29980.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85e7624f-b407-41f8-b30f-01f8bfe91c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I need to find the top three most costly procedures in the dataframe.\n",
      "Action: df.groupby('Procedure')['Charges'].sum().nlargest(3)\n",
      "Action Input:\u001b[0mdf.groupby('Procedure')['Charges'].sum().nlargest(3) is not a valid tool, try one of [python_repl_ast]."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m I need to use the pandas library to find the top three most costly procedures.\n",
      "Action: python_repl_ast\n",
      "Action Input: import pandas as pd; df.groupby('Procedure')['Charges'].sum().nlargest(3)\u001b[0m\u001b[36;1m\u001b[1;3mProcedure\n",
      "oxygen therapy    112456.32\n",
      "bypass surgery     32999.17\n",
      "clot removal       23949.17\n",
      "\u001b[32;1m\u001b[1;3m I now know the top three most costly procedures.\n",
      "Final Answer: The top three most costly procedures are 'oxygen therapy', 'bypass surgery', and 'clot removal'.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'What are the top three most costly procedures?', 'output': \"The top three most costly procedures are 'oxygen therapy', 'bypass surgery', and 'clot removal'.\"}\n"
     ]
    }
   ],
   "source": [
    "res = agent.invoke(\"What are the top three most costly procedures?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d5ad6c-d07e-40fc-91f6-f5a61613f2c6",
   "metadata": {},
   "source": [
    "##### Correct answer:  most costly procedures are 'oxygen therapy', 'bypass surgery', and 'clot removal'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf194d7-4f58-451e-8f1a-e8112086d56f",
   "metadata": {},
   "source": [
    "### Create visualizations of data using LLM and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3af52d3a-b6ee-44b3-b589-64d1987d0140",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to use pandas to extract the age column and then use matplotlib to plot a histogram.\n",
      "Action: python_repl_ast\n",
      "Action Input: import matplotlib.pyplot as plt; df['Age'].hist()\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36;1m\u001b[1;3mAxes(0.125,0.11;0.775x0.77)\u001b[0m"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m The histogram has been plotted but the output is not shown in the repl. I need to display it.\n",
      "Action: python_repl_ast\n",
      "\u001b[32;1m\u001b[1;3m I now know the final answer\u001b[0m\n",
      "Final Answer: The histogram of the age distribution of the patients is displayed above.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'input': 'Plot a histogram of the age distribution of the patients.', 'output': 'The histogram of the age distribution of the patients is displayed above.'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = agent.invoke(\"Plot a histogram of the age distribution of the patients.\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9605f3-f202-49f5-b41e-ec704e66b296",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mThought: I need to use the value_counts() method to get the number of occurrences of each procedure, and then normalize those counts to percentages. After that, I can use matplotlib to create a pie chart.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['Procedure'].value_counts().sort_index().div(df['Procedure'].value_counts().sum()).reset_index().rename(columns={'index': 'Procedure', 'Procedure': 'Label', 0: 'Percentage'}).to_frame()\u001b[0m\u001b[36;1m\u001b[1;3mAttributeError: 'DataFrame' object has no attribute 'to_frame'\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m It seems that the 'to_frame()' method is not available in the version of pandas I'm using. Instead, I can use the'melt()' method to reshape the dataframe, and then use 'to_dict()' to convert it to a dictionary, which can be passed to matplotlib.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['Procedure'].value_counts().sort_index().div(df['Procedure'].value_counts().sum()).reset_index().rename(columns={'index': 'Procedure', 'Procedure': 'Label'}).melt(id_vars='Procedure', value_vars='Procedure', var_name='Variable', value_name='Value').to_dict('records')\u001b[0m\u001b[36;1m\u001b[1;3mKeyError: \"The following id_vars or value_vars are not present in the DataFrame: ['Procedure', 'Procedure']\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m It seems that I need to specify the correct names for 'id_vars' and 'value_vars' in the'melt()' method.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['Procedure'].value_counts().sort_index().div(df['Procedure'].value_counts().sum()).reset_index().rename(columns={'index': 'Procedure', 'Procedure': 'Label'}).melt(id_vars='Procedure', value_vars='Label', var_name='Variable', value_name='Value').to_dict('records')\u001b[0m\u001b[36;1m\u001b[1;3mKeyError: \"The following id_vars or value_vars are not present in the DataFrame: ['Procedure']\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m It seems that I need to specify the correct name for 'id_vars' in the'melt()' method.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['Procedure'].value_counts().sort_index().div(df['Procedure'].value_counts().sum()).reset_index().rename(columns={'index': 'Procedure', 'Procedure': 'Label'}).melt(id_vars='index', value_vars='Procedure', var_name='Variable', value_name='Value').to_dict('records')\u001b[0m\u001b[36;1m\u001b[1;3mKeyError: \"The following id_vars or value_vars are not present in the DataFrame: ['index', 'Procedure']\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m It seems that I need to use the correct names of the columns in the original dataframe.\n",
      "Action: python_repl_ast\n",
      "Action Input: df['Procedure'].value_counts().sort_index().div(df['Procedure'].value_counts().sum()).reset_index().rename(columns={'index': 'Procedure', 'Procedure': 'Label'}).melt(id_vars='index', value_vars='Procedure', var_name='Variable', value_name='Value').to_dict('records')\u001b[0m\u001b[36;1m\u001b[1;3mKeyError: \"The following id_vars or value_vars are not present in the DataFrame: ['index', 'Procedure']\"\u001b[0m"
     ]
    }
   ],
   "source": [
    "# 경우에 따라 실행이 안되는 경우가 있습니다.\n",
    "res = agent.invoke(\"Plot a pie chart of the number of procedures based on percentage.\")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
