{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7dc7e39-dd9a-43e3-8d9a-f77af583004c",
   "metadata": {},
   "source": [
    "### Dell Technologies Proof of Concept - CHAT, ANALYZE AND GRAPH YOUR CSV DATA WITH MISTRAL LLM\n",
    "- Model:  Mistral instruct v2\n",
    "- Workload:  CSV analysis using LLM\n",
    "- Orchestrator:  Langchain csv agent\n",
    "- Dataset:  hospital visits\n",
    "\n",
    "Note: The software and sample files are provided “as is” and are to be used only in conjunction with this POC application. They should not be used in production and are provided without warranty or guarantees. Please use them at your own discretion.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbcd722",
   "metadata": {},
   "source": [
    "### Huggingface tools\n",
    "\n",
    "You will need to at least log in once to get the hub for tools and the embedding model.  After that you can comment this section out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89d4d542-e238-4948-ade3-efb972c78cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token is valid (permission: fineGrained).\n",
      "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
      "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
      "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
      "\n",
      "git config --global credential.helper store\n",
      "\n",
      "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
      "Token has not been saved to git credential helper.\n",
      "Your token has been saved to /home/daol/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "## code to auto login to hugging face, avoid the login prompt\n",
    "# %pip install huggingface-hub==0.16.4\n",
    "# %pip install --upgrade huggingface-hub\n",
    "\n",
    "# get your account token from https://huggingface.co/settings/tokens\n",
    "# this is a read-only test token\n",
    "\n",
    "token = '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'\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=token, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374ef44c-9f78-42de-9535-a47b9f8b7889",
   "metadata": {},
   "source": [
    "### Install python libraries and applications\n",
    "\n",
    "Using % to ensure installation into this conda environment and not OS python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ac77491-212f-450d-ae73-2448c3422379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install accelerate  ## for use of device map feature\n",
    "# %pip install transformers\n",
    "# %pip install langchain\n",
    "# %pip install langchain_experimental==0.0.51\n",
    "# %pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b1132dd-4463-45fe-997f-2136c13464af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check installed GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a0a0592-b751-4f5c-b97c-5cd12e8baef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 30 08:22:03 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.120                Driver Version: 550.120        CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L40S                    Off |   00000000:61:00.0 Off |                    0 |\n",
      "| N/A   36C    P0             82W /  350W |    3927MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  NVIDIA L40S                    Off |   00000000:E1:00.0 Off |                    0 |\n",
      "| N/A   28C    P8             31W /  350W |       4MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A   2600672      C   /app/.venv/bin/python3                       3920MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbb3e4a-af6a-4852-98a0-97afaff2924c",
   "metadata": {},
   "source": [
    "### Assign GPU environment vars and ID order\n",
    "\n",
    "NOTE:  to change which GPU you want visible, simply change the CUDA VISIBLE DEVICES ID to the GPU you prefer. \n",
    "This method guarantees no confusion or misplaced workloads on any GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88bf410b-3b71-4299-8bc9-0b6fb09f4482",
   "metadata": {},
   "outputs": [],
   "source": [
    "## THESE VARIABLES MUST APPEAR BEFORE TORCH OR CUDA IS IMPORTED\n",
    "## set visible GPU devices and order of IDs to the PCI bus order\n",
    "## target the L40s that is on ID 1\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"   \n",
    "\n",
    "## this integer corresponds to the ID of the GPU, for multiple GPU use \"0,1,2,3\"...\n",
    "## to disable all GPUs, simply put empty quotes \"\"\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3846fa67-69d7-478e-995e-d16a5ba98f72",
   "metadata": {},
   "source": [
    "### Investigate our GPU and CUDA environment\n",
    "\n",
    "NOTE:  If you are only using 1 single GPU in the visibility settings above, then the active CUDA device will always be 0 since it is the only GPU seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eaec1edd-9c18-4b1f-a0e8-e3ed03b3141f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_____Python, Pytorch, Cuda info____\n",
      "__Python VERSION: 3.12.8 (main, Dec  6 2024, 19:59:28) [Clang 18.1.8 ]\n",
      "__pyTorch VERSION: 2.5.1+cu124\n",
      "__CUDA RUNTIME API VERSION\n",
      "__CUDNN VERSION: 90100\n",
      "_____nvidia-smi GPU details____\n",
      "index, name, driver_version, memory.total [MiB], memory.used [MiB], memory.free [MiB]\n",
      "0, NVIDIA L40S, 550.120, 46068 MiB, 3927 MiB, 41663 MiB\n",
      "1, NVIDIA L40S, 550.120, 46068 MiB, 4 MiB, 45586 MiB\n",
      "_____Device assignments____\n",
      "Number CUDA Devices: 1\n",
      "Current cuda device:  0  **May not correspond to nvidia-smi ID above, check visibility parameter\n",
      "Device name:  NVIDIA L40S\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from subprocess import call\n",
    "print('_____Python, Pytorch, Cuda info____')\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA RUNTIME API VERSION')\n",
    "#os.system('nvcc --version')\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('_____nvidia-smi GPU details____')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('_____Device assignments____')\n",
    "print('Number CUDA Devices:', torch.cuda.device_count())\n",
    "print ('Current cuda device: ', torch.cuda.current_device(), ' **May not correspond to nvidia-smi ID above, check visibility parameter')\n",
    "print(\"Device name: \", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bae0d5-b6ef-425b-9e29-13393a839bcf",
   "metadata": {},
   "source": [
    "### Assign single GPU to device variable\n",
    "\n",
    "This command assigns GPU ID 0 to the DEVICE variable called \"cuda:0\" if pytorch can actually reach and speak with the GPU using cuda language.  Else it will use the cpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c26efcc3-328c-49fe-9fe6-bbdbec423b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc64b727-3bae-4f17-a0b9-35a29915b2df",
   "metadata": {},
   "source": [
    "### View csv contents and structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f9d50b3-3770-4b8e-abe6-37f4997cd6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('csv-files/healthcare.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad16fefb-1399-47b0-a7e6-6a55be010f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient Name Date of Birth  Age Reason for Admission       Procedure  \\\n",
      "0    Patient_3      8/6/2004   19                COVID  antiviral meds   \n",
      "1   Patient_39     3/19/2004   19                COVID  oxygen therapy   \n",
      "2   Patient_33     12/8/2002   21                COVID  oxygen therapy   \n",
      "\n",
      "       Room Date of Discharge  Length of Stay   Charges  Balance Remaining  \n",
      "0  Room_237        12/27/2023               0    237.34              37.34  \n",
      "1  Room_440         1/12/2024              22  29980.84            3018.84  \n",
      "2  Room_298        12/31/2023               6   4028.77            2681.26  \n"
     ]
    }
   ],
   "source": [
    "df_rows = df.head(3)\n",
    "print(df_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afe93d0-0641-4a57-8efb-bb8a4941dfdc",
   "metadata": {},
   "source": [
    "### Import CSV agent dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76ae7daa-2150-4880-82c5-4046a8a5ce95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "from langchain_experimental.agents.agent_toolkits import create_csv_agent\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f02c7468-c1e5-4553-8573-4eca197c4f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.globals import set_verbose, set_debug\n",
    "# set_debug(True)\n",
    "# set_verbose(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281d086e-cc14-4635-b466-f02637bb80c6",
   "metadata": {},
   "source": [
    "### Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9ecb659-43a1-49fd-9bcd-ddf0e128b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"mistralai/Mistral-7B-Instruct-v0.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf2bce85-0888-44a0-ac76-27e027c7c40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78eceb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "### https://huggingface.co/docs/transformers/en/main_classes/quantization\n",
    "\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=compute_dtype,\n",
    "#        bnb_4bit_use_double_quant=True,\n",
    ") #! 원래 코드에 옵션으로 양자화 넣기\n",
    "quantize = False\n",
    "if quantize:\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "            model, \n",
    "            quantization_config=bnb_config, \n",
    "            device_map=\"auto\"\n",
    "    )\n",
    "#Configure the pad token in the model\n",
    "# model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85df2ef-09b6-4427-8f84-90aafd3d19c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229a057c57b5460bba7eef373d526719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc0b50148cc495aa49771a8a16e65f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:  25%|##5       | 1.27G/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5876e66c2c944c35878d3deb5c15c277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    max_new_tokens=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c127e37-8966-4e22-95a0-029a4dc56a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = HuggingFacePipeline(pipeline=pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1be1e379-f815-4d8d-829f-74209644a401",
   "metadata": {},
   "source": [
    "### Initiate CSV agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14f21f5-b9ca-4fea-9c3c-7905d52d55e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_csv_agent(\n",
    "    local_llm,\n",
    "    \"csv-files/healthcare.csv\",\n",
    "    verbose=True,\n",
    "#    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece424c3-875a-4e5c-be01-8d1913bb06ca",
   "metadata": {},
   "source": [
    "### Generate responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbbb292-6242-4559-852a-c6cc45f9ace9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent.invoke(\"What was the procedure for patient 3?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75466a3-381e-4edc-824a-e8f182026256",
   "metadata": {},
   "source": [
    "##### Compare to correct answer:  antiviral meds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1624664a-c9a3-49ae-b471-eef40280653c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent.invoke(\"What was date of discharge and length of stay for patient 21?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02bf661-f6ac-493f-b65c-da697be1f423",
   "metadata": {},
   "source": [
    "##### Compare to correct answer:  11/15/2023 and the length of stay was 18 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8737bedf-cdc7-4431-a199-69e0f0d8f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent.invoke(\"What are the unique reasons for admission?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db7aba0-f5ac-4831-826b-399934ef0198",
   "metadata": {},
   "source": [
    "##### Compare to correct answer:  COVID', 'Flu', 'Pneumonia', 'Heart attack', 'Stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67868a33-aed3-4fc9-829c-07e92529247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent.invoke(\"Cross reference the charges with the reason for admission to determine which reason had the highest cost.\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab652d1-5b5f-446d-abb5-71a0153af2d5",
   "metadata": {},
   "source": [
    "##### Correct answer:  highest cost was COVID, with a total cost of 29980.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e7624f-b407-41f8-b30f-01f8bfe91c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent.invoke(\"What are the top three most costly procedures?\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d5ad6c-d07e-40fc-91f6-f5a61613f2c6",
   "metadata": {},
   "source": [
    "##### Correct answer:  most costly procedures are 'oxygen therapy', 'bypass surgery', and 'clot removal'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf194d7-4f58-451e-8f1a-e8112086d56f",
   "metadata": {},
   "source": [
    "### Create visualizations of data using LLM and matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af52d3a-b6ee-44b3-b589-64d1987d0140",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent.invoke(\"Plot a histogram of the age distribution of the patients.\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9605f3-f202-49f5-b41e-ec704e66b296",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = agent.invoke(\"Plot a pie chart of the number of procedures based on percentage.\")\n",
    "print(res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
